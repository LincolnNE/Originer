# 🚨 Risk & Failure Scenarios

## ORIGINER – AI Instructor

**(Hallucination · 장애 · 신뢰 붕괴 대응 전략)**

---

## 0️⃣ 이 문서의 전제

> ❌ “문제 안 생긴다”
> 
> 
> ⭕ “문제는 반드시 생긴다. 대신 **통제**한다.”
> 

오리지너의 핵심 리스크는 **기술 실패**가 아니라

👉 **‘강사 신뢰 붕괴’**다.

---

## 1️⃣ 리스크 맵 (한 눈 요약)

| 리스크 | 영향도 | 발생 빈도 |
| --- | --- | --- |
| 환각(Hallucination) | 🔴 매우 높음 | 중 |
| 강사 스타일 붕괴 | 🔴 매우 높음 | 중 |
| 틀린 교육 | 🔴 매우 높음 | 낮 |
| 세션 맥락 소실 | 🟠 높음 | 중 |
| 응답 지연 | 🟡 중 | 중 |
| 학생 과의존 | 🟠 높음 | 높 |

---

## 2️⃣ 시나리오 ① 환각 (Hallucination)

### 💥 상황

- 존재하지 않는 개념 설명
- 강의 범위 밖 내용 생성
- 강사가 안 한 말을 한 것처럼 말함

### 😱 최악의 결과

> “이 강사 수준이 이거야?”
> 
> 
> → **강사 브랜드 파괴**
> 

---

### 🛡 대응 전략

### 1. **지식 스코프 강제**

- Instructor curriculum 밖 질문 → 설명 금지

### 2. **“모른다” 응답 강제**

```
"이건 내가 아직 다루지 않은 내용이야.
지금 단계에서는 여기까지만 가는 게 좋아."

```

### 3. Response Validator

- 출처 없는 주장 차단
- 규칙 위반 즉시 fallback

📌 **중요**

> 환각보다 더 위험한 건
> 
> 
> **자신감 있게 틀리는 것**
> 

---

## 3️⃣ 시나리오 ② 강사 스타일 붕괴

### 💥 상황

- 갑자기 GPT 말투
- 학술적 문장
- 강사가 안 쓰는 비유 등장

### 😱 결과

> “이거 그냥 챗봇 아니야?”
> 

---

### 🛡 대응 전략

### 1. 프롬프트 계층 분리 (이미 설계됨)

- System / Identity / Rules 분리

### 2. 스타일 체크 Validator

- 말투 패턴 검사
- 어휘 분포 검사

### 3. 강사 수동 피드백 루프

- ❌ / ⭕ 체크
- 반영 → Prompt 업데이트

📌 **운영 팁**

> 강사 AI는 학습시키는 게 아니라 길들이는 것
> 

---

## 4️⃣ 시나리오 ③ 틀린 교육 (Silent Failure)

### 💥 상황

- 그럴듯하지만 논리 오류
- 교육적으로 잘못된 순서

### 😱 결과

- 학생은 틀린 걸 “이해했다고 착각”

---

### 🛡 대응 전략

### 1. **정답 회피 규칙**

- 항상 질문 유도
- 중간 사고 과정 확인

### 2. 학습 확인 질문 강제

```
"여기까지 이해한 걸 네 말로 말해볼래?"

```

### 3. 고위험 개념 Flag

- 재귀, 포인터, 확률 등
    
    → 보수적 설명 모드
    

---

## 5️⃣ 시나리오 ④ 세션 맥락 소실

### 💥 상황

- “아까 말한 거” 기억 못함
- 학생 반복 질문

### 😱 결과

> “사람이랑 수업하는 느낌이 사라짐”
> 

---

### 🛡 대응 전략

### 1. Session Orchestrator 중심 설계

- 세션 종료 전까지 컨텍스트 유지

### 2. Learner Memory 분리 저장

- 요약된 핵심만 유지 (토큰 절약)

### 3. 맥락 리마인드 응답

```
"아까 우리가 이야기한 흐름 다시 잠깐 짚어볼게."

```

---

## 6️⃣ 시나리오 ⑤ 응답 지연 / 장애

### 💥 상황

- LLM API 지연
- 스트리밍 끊김

### 😱 결과

- “서비스 불안정” 인식

---

### 🛡 대응 전략

### 1. UX 레벨 대응

- “생각 중입니다” ❌
- “설명 정리 중이에요” ⭕

### 2. 단계적 응답

- 짧은 응답 먼저
- 상세 설명 뒤따라 전송

### 3. LLM Failover

- 1차 실패 → 경량 모델

---

## 7️⃣ 시나리오 ⑥ 학생 과의존 (의외로 중요)

### 💥 상황

- 스스로 생각 안 함
- 답만 요구

### 😱 결과

- 교육 서비스 신뢰 하락
- “AI가 대신 해준다” 인식

---

### 🛡 대응 전략

### 1. 답변 거부 UX

```
"이건 네가 직접 생각해보는 게 좋아.
내가 방향만 잡아줄게."

```

### 2. 질문형 응답 비율 유지

- 선언문 < 질문문

### 3. 일정 횟수 이상 → 난이도 상승

---

## 8️⃣ 운영 중 반드시 해야 할 모니터링

### 📊 실시간 체크 지표

- fallback 발생률
- 강사 ❌ 클릭 비율
- “이해 안 됨” 반복 횟수

### 🚨 알람 기준

- 특정 개념 fallback 급증
- 특정 강사 스타일 이탈

---

## 9️⃣ VC가 좋아하는 한 줄

> “우리는 AI 실패를 막지 않습니다.대신, 실패를 사람 강사처럼 안전하게 처리합니다.”
> 

---

## 🔥 최종 요약

- 오리지너의 리스크는 **기술**이 아니라 **신뢰**
- 모든 대응의 기준은 **강사 관점**
- “완벽한 AI” ❌
- **“실수해도 믿을 수 있는 강사” ⭕**

---

이제 남은 건 **진짜 상용 준비**다.

다음 단계는 여기 중 하나가 자연스럽다 👇

- **9️⃣ MVP → 상용 전환 체크리스트**
- **10️⃣ 강사 온보딩 플레이북 (영업·파트너용)**
- **11️⃣ 조직·채용 설계 (초기 팀 구성)**